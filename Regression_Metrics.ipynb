{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgift2q6GM7W"
      },
      "source": [
        "### Boston Housing Data\n",
        "\n",
        "In order to gain a better understanding of the metrics used in regression settings, we will be looking at the Boston Housing dataset.  \n",
        "\n",
        "First use the cell below to read in the dataset and set up the training and testing data that will be used for the rest of this problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XBRdeIVGM7Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tests2 as t\n",
        "\n",
        "boston = load_boston()\n",
        "y = boston.target\n",
        "X = boston.data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LQEQKrQGM7b",
        "outputId": "90dae78a-614c-48be-cd66-a47021088bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "That's right!  All but logistic regression can be used for predicting numeric values.  And linear regression is the only one of these that you should not use for predicting categories.  Technically sklearn won't stop you from doing most of anything you want, but you probably want to treat cases in the way you found by answering this question!\n"
          ]
        }
      ],
      "source": [
        "# When can you use the model - use each option as many times as necessary\n",
        "a = 'regression'\n",
        "b = 'classification'\n",
        "c = 'both regression and classification'\n",
        "\n",
        "models = {\n",
        "    'decision trees':c, # Letter here,\n",
        "    'random forest':c, # Letter here,\n",
        "    'adaptive boosting':c, # Letter here,\n",
        "    'logistic regression':b, # Letter here,\n",
        "    'linear regression':a # Letter here\n",
        "}\n",
        "\n",
        "#checks your answer, no need to change this code\n",
        "t.q1_check(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "963eiXiXGM7c"
      },
      "outputs": [],
      "source": [
        "# Import models from sklearn - notice you will want to use\n",
        "# the regressor version (not classifier) - googling to find\n",
        "# each of these is what we all do!\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnUTlgjRGM7d"
      },
      "outputs": [],
      "source": [
        "# Instantiate each of the models you imported\n",
        "# For now use the defaults for all the hyperparameters\n",
        "reg_mod= LinearRegression()\n",
        "tree_mod= DecisionTreeRegressor()\n",
        "rf_mod= RandomForestRegressor()\n",
        "ada_mod= AdaBoostRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob9U6mbSGM7e",
        "outputId": "8fd1b33e-43d8-4d54-dcb5-7a5f04ab9899"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
              "         n_estimators=50, random_state=None)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit each of your models using the training data\n",
        "reg_mod.fit(X_train, y_train)\n",
        "tree_mod.fit(X_train, y_train)\n",
        "rf_mod.fit(X_train, y_train)\n",
        "ada_mod.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMKNkjs1GM7e"
      },
      "outputs": [],
      "source": [
        "# Predict on the test values for each model\n",
        "reg_preds= reg_mod.predict(X_test)\n",
        "tree_preds= tree_mod.predict(X_test)\n",
        "rf_preds= rf_mod.predict(X_test)\n",
        "ada_preds= ada_mod.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TpJH4q1GM7f",
        "outputId": "2eac6095-30ce-436c-a194-69fdad1002cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "That's right! Looks like you know your metrics!\n"
          ]
        }
      ],
      "source": [
        "# potential model options\n",
        "a = 'regression'\n",
        "b = 'classification'\n",
        "c = 'both regression and classification'\n",
        "\n",
        "#\n",
        "metrics = {\n",
        "    'precision':b, # Letter here,\n",
        "    'recall':b, # Letter here,\n",
        "    'accuracy':b, # Letter here,\n",
        "    'r2_score':a, # Letter here,\n",
        "    'mean_squared_error':a, # Letter here,\n",
        "    'area_under_curve':b, # Letter here,\n",
        "    'mean_absolute_area':a # Letter here\n",
        "}\n",
        "\n",
        "#checks your answer, no need to change this code\n",
        "t.q6_check(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55MasMZRGM7f"
      },
      "outputs": [],
      "source": [
        "# Import the metrics from sklearn\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWvOseatGM7g",
        "outputId": "147bfff2-e096-403e-8474-1b3a44995e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.736729850468\n",
            "0.736729850468\n",
            "Since the above match, we can see that we have correctly calculated the r2 value.\n"
          ]
        }
      ],
      "source": [
        "def r2(actual, preds):\n",
        "    '''\n",
        "    INPUT:\n",
        "    actual - numpy array or pd series of actual y values\n",
        "    preds - numpy array or pd series of predicted y values\n",
        "    OUTPUT:\n",
        "    returns the r-squared score as a float\n",
        "    '''\n",
        "    sse = np.sum((actual-preds)**2)\n",
        "    sst = np.sum((actual-np.mean(actual))**2)\n",
        "    return 1 - sse/sst\n",
        "\n",
        "# Check solution matches sklearn\n",
        "print(r2(y_test, tree_preds))\n",
        "print(r2_score(y_test, tree_preds))\n",
        "print(\"Since the above match, we can see that we have correctly calculated the r2 value.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmxMkg0VGM7g",
        "outputId": "58aef694-9187-4607-8324-3497eb20e3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19.9238922156\n",
            "19.9238922156\n",
            "If the above match, you are all set!\n"
          ]
        }
      ],
      "source": [
        "def mse(actual, preds):\n",
        "    '''\n",
        "    INPUT:\n",
        "    actual - numpy array or pd series of actual y values\n",
        "    preds - numpy array or pd series of predicted y values\n",
        "    OUTPUT:\n",
        "    returns the mean squared error as a float\n",
        "    '''\n",
        "\n",
        "    return sum((actual-preds)**2)/len(actual)\n",
        "\n",
        "\n",
        "# Check your solution matches sklearn\n",
        "print(mse(y_test, tree_preds))\n",
        "print(mean_squared_error(y_test, tree_preds))\n",
        "print(\"If the above match, you are all set!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2h2WSUnGM7h",
        "outputId": "87a62bc5-ee9b-4da9-d3be-64ddc0200c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.1119760479\n",
            "3.1119760479\n",
            "If the above match, you are all set!\n"
          ]
        }
      ],
      "source": [
        "def mae(actual, preds):\n",
        "    '''\n",
        "    INPUT:\n",
        "    actual - numpy array or pd series of actual y values\n",
        "    preds - numpy array or pd series of predicted y values\n",
        "    OUTPUT:\n",
        "    returns the mean absolute error as a float\n",
        "    '''\n",
        "\n",
        "    return sum(np.abs(actual-preds))/len(actual)\n",
        "\n",
        "# Check your solution matches sklearn\n",
        "print(mae(y_test, tree_preds))\n",
        "print(mean_absolute_error(y_test, tree_preds))\n",
        "print(\"If the above match, you are all set!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLqjStZcGM7h",
        "outputId": "05403884-0f0a-495f-ac02-a2405ec6cbd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Oops!  Actually the best model was the same for all the metrics.  Try again - all of your answers should be the same!\n"
          ]
        }
      ],
      "source": [
        "#match each metric to the model that performed best on it\n",
        "a = 'decision tree'\n",
        "b = 'random forest'\n",
        "c = 'adaptive boosting'\n",
        "d = 'linear regression'\n",
        "\n",
        "\n",
        "best_fit = {\n",
        "    'mse':b, # letter here,\n",
        "    'r2':b, # letter here,\n",
        "    'mae':a # letter here\n",
        "}\n",
        "\n",
        "#Tests your answer - don't change this code\n",
        "t.check_ten(best_fit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GCp5Qb3GM7i"
      },
      "outputs": [],
      "source": [
        "# cells for work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqjUQJnQGM7i"
      },
      "outputs": [],
      "source": [
        "def print_metrics(y_true, preds, model_name=None):\n",
        "    if model_name == None:\n",
        "        print('Mean Square Error: ', format(mean_squared_error(y_true,preds)))\n",
        "        print('Mean Absolute Error: ', format(mean_absolute_error(y_true,preds)))\n",
        "        print('R2 Score: ', format(r2_score(y_true,preds)))\n",
        "        print('\\n\\n')\n",
        "    else:\n",
        "        print('Mean Square Error for ',model_name,': ', format(mean_squared_error(y_true,preds)))\n",
        "        print('Mean Absolute Error for ',model_name,': ', format(mean_absolute_error(y_true,preds)))\n",
        "        print('R2 Score: ',model_name,': ', format(r2_score(y_true,preds)))\n",
        "        print('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QvlA-0iGM7i",
        "outputId": "f7d242b1-87fc-4bd8-abba-d7147ff58fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Square Error for  tree :  19.923892215568863\n",
            "Mean Absolute Error for  tree :  3.111976047904192\n",
            "R2 Score:  tree :  0.7367298504681555\n",
            "\n",
            "\n",
            "\n",
            "Mean Square Error for  Random Forest :  10.616735329341317\n",
            "Mean Absolute Error for  Random Forest :  2.2094610778443116\n",
            "R2 Score:  Random Forest :  0.8597126772492982\n",
            "\n",
            "\n",
            "\n",
            "Mean Square Error for  Adaboost :  14.300630055624195\n",
            "Mean Absolute Error for  Adaboost :  2.745461844844545\n",
            "R2 Score:  Adaboost :  0.8110344619209597\n",
            "\n",
            "\n",
            "\n",
            "Mean Square Error for  Linear Regression :  20.747143360309067\n",
            "Mean Absolute Error for  Linear Regression :  3.1512878365884154\n",
            "R2 Score:  Linear Regression :  0.7258515818230032\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_metrics(y_test, tree_preds, 'tree')\n",
        "print_metrics(y_test, rf_preds, 'Random Forest')\n",
        "print_metrics(y_test, ada_preds, 'Adaboost')\n",
        "print_metrics(y_test, reg_preds, 'Linear Regression')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWOGJKl2GM7i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}